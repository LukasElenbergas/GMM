{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM PROJECT 1 \n",
    "*Lukas Elenbergas, 1712238*\n",
    "\n",
    "Variant: **Car, Cat, Guitar**\n",
    "\n",
    "***Task***: Using an already existing pre-trained model calculate accuracy, precision, recall and F1 scores for a 1000 images from the OpenImages dataset by utilizing an effective data loader. The program should implement a threshold changer. The scores have to recalculate after thresholds changing.\n",
    " \n",
    "The data classes must be picked from [OpenImages V6](https://storage.googleapis.com/openimages/web/index.html) classification task dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# IMPORTS\n",
    "# ---------------------------------------------------\n",
    "# Fiftyone package install for the Collab environment\n",
    "'''!pip install fiftyone'''\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "# ---------------------------------------------------\n",
    "# ENVIRONMENT VARIABLES\n",
    "# ---------------------------------------------------\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "IMAGE_PATH = 'C:\\\\Projects\\\\GMM\\\\Images\\\\'\n",
    "CLASS_PATH = 'C:\\\\Projects\\\\GMM\\\\Other\\\\imagenet_classes_modified.txt'\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# HELPER FUNCTION\n",
    "# ---------------------------------------------------\n",
    "def ground_truth_array_generation(labels):\n",
    "    temporary_array = [0, 0, 0]\n",
    "\n",
    "    if 'Car' in labels:\n",
    "        temporary_array[0] = 1\n",
    "    if 'Cat' in labels:\n",
    "        temporary_array[1] = 1\n",
    "    if 'Guitar' in labels:\n",
    "        temporary_array[2] = 1\n",
    "\n",
    "    return np.array(temporary_array)\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# FIFTYONE DATASET\n",
    "# ---------------------------------------------------\n",
    "def create_fo_dataset(\n",
    "        dataset_name: str,\n",
    "        dataset_type: str,\n",
    "        dataset_samp: int,\n",
    "):\n",
    "    # Fiftyone dataset creation by loading OpenImages V6 dataset from the FO Zoo collection \n",
    "    dataset = foz.load_zoo_dataset(\n",
    "        'open-images-v6',\n",
    "        dataset_type,\n",
    "        label_types='classifications',\n",
    "        classes=['Car', 'Cat', 'Guitar'],\n",
    "        only_matching=True,\n",
    "        max_samples=dataset_samp,\n",
    "        dataset_name=dataset_name\n",
    "    )\n",
    "\n",
    "    # Making the ground truth detection easier to access by appending all lables of the image into one list\n",
    "    for sample in dataset:\n",
    "        sample['labels'] = []\n",
    "        for item in sample.positive_labels.classifications:\n",
    "            sample['labels'].append(item.label)\n",
    "        sample['ground_truth'] = ground_truth_array_generation(sample.labels)\n",
    "        sample.save()\n",
    "\n",
    "    return dataset\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# TORCH DATASET\n",
    "# ---------------------------------------------------\n",
    "class ClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, label_field='ground_truth'):\n",
    "        self.samples = data\n",
    "        self.label_field = label_field\n",
    "        self.img_paths = self.samples.values('filepath')\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.CenterCrop((1024, 1024)),\n",
    "            transforms.Resize((256, 256), interpolation=F.InterpolationMode.BILINEAR, antialias=True),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        sample = self.samples[img_path]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        ground_truth = sample[self.label_field]\n",
    "        image_tensor = self.transforms(image)\n",
    "\n",
    "        return { 'image': image_tensor, 'ground_truth': ground_truth}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def sample_path(self, idx):\n",
    "        return self.img_paths[idx]\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\GMM\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\GMM\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# PREP\n",
    "# ---------------------------------------------------\n",
    "# MODEL AND DEVICE INIT\n",
    "# ---------------------------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.vgg19(pretrained=True).to(device)\n",
    "model.eval()\n",
    "# ---------------------------------------------------\n",
    "# DATASET INIT\n",
    "# ---------------------------------------------------\n",
    "reset_required = False\n",
    "if reset_required:\n",
    "    fo.delete_dataset('Testing_1')\n",
    "if 'Testing_1' in fo.list_datasets():\n",
    "    fo_dataset = fo.load_dataset('Testing_1')\n",
    "else:\n",
    "    fo_dataset = create_fo_dataset('Testing_1', 'test', 1000)\n",
    "testing_dataset = ClassificationDataset(fo_dataset)\n",
    "# ---------------------------------------------------\n",
    "# TRANSFORMATIONS FOR IMAGES\n",
    "# ---------------------------------------------------\n",
    "all_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224), antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "# ---------------------------------------------------\n",
    "# GETTING THE ACTUAL LABELS FROM THE TEXT FILE\n",
    "# ---------------------------------------------------\n",
    "with open(CLASS_PATH, 'r') as fid:\n",
    "    all_labels = [ln.strip() for ln in fid]\n",
    "# ---------------------------------------------------\n",
    "# FUNCTION TO RETURN THE READABLE LABELS\n",
    "# ---------------------------------------------------\n",
    "def readable_predictions(predicted_classes):\n",
    "    predicted_labels = []\n",
    "    match predicted_classes.size:\n",
    "        case 0:\n",
    "            predicted_labels.append(\"none\")\n",
    "        case 1:\n",
    "            predicted_labels.append(all_labels[predicted_classes])\n",
    "        case _ if predicted_classes.size > 1:\n",
    "            for item in predicted_classes:\n",
    "                predicted_labels.append(all_labels[item])\n",
    "    return predicted_labels\n",
    "# ---------------------------------------------------\n",
    "# FUNCTION TO RETURN INDICES OF PREDICTED CLASSES\n",
    "# ---------------------------------------------------\n",
    "def get_indices(thresholded_output):\n",
    "    number_of_classes = thresholded_output.count_nonzero()\n",
    "    _, predicted_classes = torch.topk(thresholded_output, number_of_classes)\n",
    "    predicted_classes = predicted_classes.cpu().numpy().squeeze()\n",
    "\n",
    "    return predicted_classes\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.807, 'recall': 0.42273180458624127, 'precision': 1.0, 'F1': 0.5942536790469516}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# THRESHOLD AND METRICS\n",
    "# ---------------------------------------------------\n",
    "threshold = 0.5\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "# ---------------------------------------------------\n",
    "# CALCULATING STATS\n",
    "# ---------------------------------------------------\n",
    "for data_item in testing_dataset:\n",
    "    # Getting the output tensor from the model and thresholding it\n",
    "    input_image = data_item['image'].unsqueeze(0).to(device)\n",
    "    output = model(input_image)\n",
    "    output = torch.softmax(output, dim=1)\n",
    "    thresholded_output = (output >= threshold).int()\n",
    "    # Getting the indices of predicted classes\n",
    "    predicted_classes = get_indices(thresholded_output)\n",
    "    # Getting the actual labels of predicted classes\n",
    "    predicted_labels = readable_predictions(predicted_classes)\n",
    "    # Formatting the labels into an array comparable to the ground truth\n",
    "    predicted_ground_truth = ground_truth_array_generation(predicted_labels)\n",
    "    # Calculating TP, TN, FP, FN\n",
    "    TP += np.sum(np.bitwise_and(data_item['ground_truth'] == 1, predicted_ground_truth == 1))\n",
    "    TN += np.sum(np.bitwise_and(data_item['ground_truth'] == 0, predicted_ground_truth == 0))\n",
    "    FP += np.sum(np.bitwise_and(data_item['ground_truth'] == 0, predicted_ground_truth == 1))\n",
    "    FN += np.sum(np.bitwise_and(data_item['ground_truth'] == 1, predicted_ground_truth == 0))\n",
    "\n",
    "metrics = {}\n",
    "metrics['accuracy'] = (TP + TN) / (TP + FP + TN + FN)\n",
    "metrics['recall'] = TP / (TP + FN)\n",
    "metrics['precision'] = TP / (TP + FP)\n",
    "metrics['F1'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'])\n",
    "\n",
    "print(metrics)\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Car']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# IMAGE PREP BEFORE PASSING TO MODEL\n",
    "# ---------------------------------------------------\n",
    "image = Image.open(IMAGE_PATH + '8.jpg')\n",
    "image = all_transforms(image).unsqueeze(0).to(device)\n",
    "# ---------------------------------------------------\n",
    "# LOCAL THRESHOLD\n",
    "# ---------------------------------------------------\n",
    "local_threshold = 0.5\n",
    "# ---------------------------------------------------\n",
    "# PREDICTING THE CLASS USING THE PRETRAINED MODEL\n",
    "# ---------------------------------------------------\n",
    "output = model(image)\n",
    "output = torch.softmax(output, dim=1)\n",
    "thresholded_output = (output > local_threshold).int()\n",
    "predicted_classes = get_indices(thresholded_output)\n",
    "predicted_labels = readable_predictions(predicted_classes)\n",
    "print(predicted_labels)\n",
    "# ---------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GMM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
